# (c) Copyright [2018-2020] Micro Focus or one of its affiliates.
# Licensed under the Apache License, Version 2.0 (the "License");
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# |_     |~) _  _| _  /~\    _ |.
# |_)\/  |_)(_|(_||   \_/|_|(_|||
#    /
#              ____________       ______
#             / __        `\     /     /
#            |  \/         /    /     /
#            |______      /    /     /
#                   |____/    /     /
#          _____________     /     /
#          \           /    /     /
#           \         /    /     /
#            \_______/    /     /
#             ______     /     /
#             \    /    /     /
#              \  /    /     /
#               \/    /     /
#                    /     /
#                   /     /
#                   \    /
#                    \  /
#                     \/
#                    _
# \  / _  __|_. _ _ |_)
#  \/ (/_|  | |(_(_|| \/
#                     /
# VerticaPy is a Python library with scikit-like functionality to use to conduct
# data science projects on data stored in Vertica, taking advantage Vertica’s
# speed and built-in analytics and machine learning features. It supports the
# entire data science life cycle, uses a ‘pipeline’ mechanism to sequentialize
# data transformation operations, and offers beautiful graphical options.
#
# VerticaPy aims to solve all of these problems. The idea is simple: instead
# of moving data around for processing, VerticaPy brings the logic to the data.
#
#
# Modules
#
# VerticaPy Modules
from verticapy.learn.metrics import *
from verticapy.learn.plot import *
from verticapy.utilities import *
from verticapy.toolbox import *
from verticapy import vDataFrame
from verticapy.learn.plot import lof_plot
from verticapy.connections.connect import read_auto_connect
from verticapy.errors import *
from verticapy.learn.vmodel import *

# ---#
class NearestCentroid:
    """
---------------------------------------------------------------------------
[Beta Version]
Creates a NearestCentroid object by using the K Nearest Centroid Algorithm. 
This object is using pure SQL to compute all the distances and final score. 

\u26A0 Warning : As NearestCentroid is using the p-distance, it is highly 
                 sensible to un-normalized data.  

Parameters
----------
cursor: DBcursor, optional
	Vertica DB cursor. 
p: int, optional
	The p corresponding to the one of the p-distance (distance metric used 
	during the model computation).

Attributes
----------
After the object creation, all the parameters become attributes. 
The model will also create extra attributes when fitting the model:

centroids: tablesample
	The final centroids.
classes: list
	List of all the response classes.
input_relation: str
	Train relation.
X: list
	List of the predictors.
y: str
	Response column.
test_relation: str
	Relation to use to test the model. All the model methods are abstractions
	which will simplify the process. The test relation will be used by many
	methods to evaluate the model. If empty, the train relation will be 
	used as test. You can change it anytime by changing the test_relation
	attribute of the object.
	"""

    #
    # Special Methods
    #
    # ---#
    def __init__(self, cursor=None, p: int = 2):
        check_types([("p", p, [int, float], False)])
        if not (cursor):
            cursor = read_auto_connect().cursor()
        else:
            check_cursor(cursor)
        self.type = "NearestCentroid"
        self.category = "classifier"
        self.cursor = cursor
        self.p = p

    # ---#
    def __repr__(self):
        try:
            rep = (
                "<NearestCentroid>\n\ncentroids:\n"
                + self.centroids.__repr__()
                + "\n\nclasses: {}".format(self.classes)
            )
            return rep
        except:
            return "<NearestCentroid>"

    #
    # Methods
    #
    # ---#
    def classification_report(self, cutoff=[], labels: list = []):
        """
	---------------------------------------------------------------------------
	Computes a classification report using multiple metrics to evaluate the model
	(AUC, accuracy, PRC AUC, F1...). In case of multiclass classification, it will 
	consider each category as positive and switch to the next one during the computation.

	Parameters
	----------
	cutoff: float/list, optional
		Cutoff for which the tested category will be accepted as prediction. 
		In case of multiclass classification, each tested category becomes 
		the positives and the others are merged into the negatives. The list will 
		represent the classes threshold. If it is empty, the best cutoff will be used.
	labels: list, optional
		List of the different labels to be used during the computation.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        check_types(
            [
                ("cutoff", cutoff, [int, float, list], False),
                ("labels", labels, [list], False),
            ]
        )
        if not (labels):
            labels = self.classes
        return classification_report(cutoff=cutoff, estimator=self, labels=labels)

    # ---#
    def confusion_matrix(self, pos_label=None, cutoff: float = -1):
        """
	---------------------------------------------------------------------------
	Computes the model confusion matrix.

	Parameters
	----------
	pos_label: int/float/str, optional
		Label to consider as positive. All the other classes will be merged and
		considered as negative in case of multi classification.
	cutoff: float, optional
		Cutoff for which the tested category will be accepted as prediction. If the 
		cutoff is not between 0 and 1, the entire confusion matrix will be drawn.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        check_types([("cutoff", cutoff, [int, float], False)])
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label in self.classes and cutoff <= 1 and cutoff >= 0:
            input_relation = self.deploySQL() + " WHERE predict_nc = '{}'".format(
                pos_label
            )
            y_score = "(CASE WHEN proba_predict > {} THEN 1 ELSE 0 END)".format(cutoff)
            y_true = "DECODE({}, '{}', 1, 0)".format(self.y, pos_label)
            result = confusion_matrix(y_true, y_score, input_relation, self.cursor)
            if pos_label == 1:
                return result
            else:
                return tablesample(
                    values={
                        "index": ["Non-{}".format(pos_label), "{}".format(pos_label)],
                        "Non-{}".format(pos_label): result.values[0],
                        "{}".format(pos_label): result.values[1],
                    },
                    table_info=False,
                )
        else:
            return multilabel_confusion_matrix(
                self.y,
                "predict_nc",
                self.deploySQL(predict=True),
                self.classes,
                self.cursor,
            )

    # ---#
    def deploySQL(self, predict: bool = False):
        """
	---------------------------------------------------------------------------
	Returns the SQL code needed to deploy the model. 

	Parameters
	----------
	predict: bool, optional
		If set to True, returns the prediction instead of the probability.

	Returns
	-------
	str/list
 		the SQL code needed to deploy the model.
		"""
        check_types([("predict", predict, [bool], False)])
        sql = [
            "POWER(ABS(x.{} - y.{}), {})".format(self.X[i], self.X[i], self.p)
            for i in range(len(self.X))
        ]
        distance = "POWER({}, 1 / {})".format(" + ".join(sql), self.p)
        sql = "ROW_NUMBER() OVER(PARTITION BY {}, row_id ORDER BY {})".format(
            ", ".join(["x.{}".format(item) for item in self.X]), distance
        )
        where = " AND ".join(["{} IS NOT NULL".format(item) for item in self.X])
        sql = "(SELECT {}, {} AS ordered_distance, {} AS distance, x.{}, y.{} AS predict_nc FROM (SELECT *, ROW_NUMBER() OVER() AS row_id FROM {} WHERE {}) x CROSS JOIN ({}) y) nc_distance_table".format(
            ", ".join(["x.{}".format(item) for item in self.X]),
            sql,
            distance,
            self.y,
            self.y,
            self.test_relation,
            where,
            self.centroids.to_sql(),
        )
        if predict:
            sql = "(SELECT {}, {}, predict_nc FROM {} WHERE ordered_distance = 1) nc_table".format(
                ", ".join(self.X), self.y, sql
            )
        else:
            sql = "(SELECT {}, {}, predict_nc, (1 - DECODE(distance, 0, 0, (distance / SUM(distance) OVER (PARTITION BY {})))) / {} AS proba_predict, ordered_distance FROM {}) nc_table".format(
                ", ".join(self.X), self.y, ", ".join(self.X), len(self.classes) - 1, sql
            )
        return sql

    # ---#
    def fit(self, input_relation: str, X: list, y: str, test_relation: str = ""):
        """
	---------------------------------------------------------------------------
	Trains the model.

	Parameters
	----------
	input_relation: str
		Train relation.
	X: list
		List of the predictors.
	y: str
		Response column.
	test_relation: str, optional
		Relation to use to test the model.

	Returns
	-------
	object
 		self
		"""
        check_types(
            [
                ("input_relation", input_relation, [str], False),
                ("X", X, [list], False),
                ("y", y, [str], False),
                ("test_relation", test_relation, [str], False),
            ]
        )
        func = "APPROXIMATE_MEDIAN" if (self.p == 1) else "AVG"
        self.input_relation = input_relation
        self.test_relation = test_relation if (test_relation) else input_relation
        self.X = [str_column(column) for column in X]
        self.y = str_column(y)
        query = "SELECT {}, {} FROM {} WHERE {} IS NOT NULL GROUP BY {} ORDER BY {} ASC".format(
            ", ".join(
                ["{}({}) AS {}".format(func, column, column) for column in self.X]
            ),
            self.y,
            input_relation,
            self.y,
            self.y,
            self.y,
        )
        self.centroids = to_tablesample(query=query, cursor=self.cursor)
        self.centroids.table_info = False
        self.classes = self.centroids.values[y]
        return self

    # ---#
    def lift_chart(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model Lift Chart.

	Parameters
	----------
	pos_label: int/float/str
		To draw a lift chart, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_nc = '{}'".format(pos_label)
        y_proba = "proba_predict"
        return lift_chart(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def prc_curve(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model PRC curve.

	Parameters
	----------
	pos_label: int/float/str
		To draw the PRC curve, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_nc = '{}'".format(pos_label)
        y_proba = "proba_predict"
        return prc_curve(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def roc_curve(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model ROC curve.

	Parameters
	----------
	pos_label: int/float/str
		To draw the ROC curve, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_nc = '{}'".format(pos_label)
        y_proba = "proba_predict"
        return roc_curve(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def score(self, pos_label=None, cutoff: float = -1, method: str = "accuracy"):
        """
	---------------------------------------------------------------------------
	Computes the model score.

	Parameters
	----------
	pos_label: int/float/str, optional
		Label to consider as positive. All the other classes will be merged and
		considered as negative in case of multi classification.
	cutoff: float, optional
		Cutoff for which the tested category will be accepted as prediction. 
	method: str, optional
		The method to use to compute the score.
			accuracy    : Accuracy
			auc         : Area Under the Curve (ROC)
			best_cutoff : Cutoff which optimised the ROC Curve prediction.
			bm          : Informedness = tpr + tnr - 1
			csi         : Critical Success Index = tp / (tp + fn + fp)
			f1          : F1 Score 
			logloss     : Log Loss
			mcc         : Matthews Correlation Coefficient 
			mk          : Markedness = ppv + npv - 1
			npv         : Negative Predictive Value = tn / (tn + fn)
			prc_auc     : Area Under the Curve (PRC)
			precision   : Precision = tp / (tp + fp)
			recall      : Recall = tp / (tp + fn)
			specificity : Specificity = tn / (tn + fp) 

	Returns
	-------
	float
 		score
		"""
        check_types(
            [("cutoff", cutoff, [int, float], False), ("method", method, [str], False)]
        )
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        input_relation = "(SELECT * FROM {} WHERE predict_nc = '{}') final_centroids_relation".format(
            self.deploySQL(), pos_label
        )
        y_score = "(CASE WHEN proba_predict > {} THEN 1 ELSE 0 END)".format(cutoff)
        y_proba = "proba_predict"
        y_true = "DECODE({}, '{}', 1, 0)".format(self.y, pos_label)
        if (pos_label not in self.classes) and (method != "accuracy"):
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        elif (cutoff >= 1 or cutoff <= 0) and (method != "accuracy"):
            cutoff = self.score(pos_label, 0.5, "best_cutoff")
        if method in ("accuracy", "acc"):
            if pos_label not in self.classes:
                return accuracy_score(
                    self.y,
                    "predict_nc",
                    self.deploySQL(True),
                    self.cursor,
                    pos_label=None,
                )
            else:
                return accuracy_score(y_true, y_score, input_relation, self.cursor)
        elif method == "auc":
            return auc(y_true, y_proba, input_relation, self.cursor)
        elif method == "prc_auc":
            return prc_auc(y_true, y_proba, input_relation, self.cursor)
        elif method in ("best_cutoff", "best_threshold"):
            return roc_curve(
                y_true, y_proba, input_relation, self.cursor, best_threshold=True
            )
        elif method in ("recall", "tpr"):
            return recall_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("precision", "ppv"):
            return precision_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("specificity", "tnr"):
            return specificity_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("negative_predictive_value", "npv"):
            return precision_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("log_loss", "logloss"):
            return log_loss(y_true, y_proba, input_relation, self.cursor)
        elif method == "f1":
            return f1_score(y_true, y_score, input_relation, self.cursor)
        elif method == "mcc":
            return matthews_corrcoef(y_true, y_score, input_relation, self.cursor)
        elif method in ("bm", "informedness"):
            return informedness(y_true, y_score, input_relation, self.cursor)
        elif method in ("mk", "markedness"):
            return markedness(y_true, y_score, input_relation, self.cursor)
        elif method in ("csi", "critical_success_index"):
            return critical_success_index(y_true, y_score, input_relation, self.cursor)
        else:
            raise ParameterError(
                "The parameter 'method' must be in accuracy|auc|prc_auc|best_cutoff|recall|precision|log_loss|negative_predictive_value|specificity|mcc|informedness|markedness|critical_success_index"
            )

    # ---#
    def to_vdf(self, cutoff: float = -1, all_classes: bool = False):
        """
	---------------------------------------------------------------------------
	Returns the vDataFrame of the Prediction.

	Parameters
	----------
	cutoff: float, optional
		Cutoff used in case of binary classification. It is the probability to
		accept the category 1.
	all_classes: bool, optional
		If set to True, all the classes probabilities will be generated (one 
		column per category).

	Returns
	-------
	vDataFrame
 		the vDataFrame of the prediction
		"""
        check_types(
            [
                ("cutoff", cutoff, [int, float], False),
                ("all_classes", all_classes, [bool], False),
            ]
        )
        if all_classes:
            predict = [
                "ZEROIFNULL(AVG(DECODE(predict_nc, '{}', proba_predict, NULL))) AS \"{}_{}\"".format(
                    elem, self.y.replace('"', ""), elem
                )
                for elem in self.classes
            ]
            sql = "SELECT {}, {} FROM {} GROUP BY {}".format(
                ", ".join(self.X),
                ", ".join(predict),
                self.deploySQL(),
                ", ".join(self.X),
            )
        else:
            if (len(self.classes) == 2) and (cutoff <= 1 and cutoff >= 0):
                sql = "SELECT {}, (CASE WHEN proba_predict > {} THEN '{}' ELSE '{}' END) AS {} FROM {} WHERE predict_nc = '{}'".format(
                    ", ".join(self.X),
                    cutoff,
                    self.classes[1],
                    self.classes[0],
                    self.y,
                    self.deploySQL(),
                    self.classes[1],
                )
            elif len(self.classes) == 2:
                sql = "SELECT {}, proba_predict AS {} FROM {} WHERE predict_nc = '{}'".format(
                    ", ".join(self.X), self.y, self.deploySQL(), self.classes[1]
                )
            else:
                sql = "SELECT {}, predict_nc AS {} FROM {}".format(
                    ", ".join(self.X), self.y, self.deploySQL(True)
                )
        sql = "({}) x".format(sql)
        return vdf_from_relation(
            name="NearestCentroid", relation=sql, cursor=self.cursor
        )


# ---#
class KNeighborsClassifier:
    """
---------------------------------------------------------------------------
[Beta Version]
Creates a KNeighborsClassifier object by using the K Nearest Neighbors Algorithm. 
This object is using pure SQL to compute all the distances and final score.

\u26A0 Warning : This Algorithm is computationally expensive. It is using a CROSS 
                 JOIN during the computation. The complexity is O(n * n), n 
                 being the total number of elements. As KNeighborsClassifier 
                 is using the p-distance, it is highly sensible to un-normalized 
                 data. 

Parameters
----------
cursor: DBcursor, optional
	Vertica DB cursor. 
n_neighbors: int, optional
	Number of neighbors to consider when computing the score.
p: int, optional
	The p corresponding to the one of the p-distance (distance metric used during 
	the model computation).

Attributes
----------
After the object creation, all the parameters become attributes. 
The model will also create extra attributes when fitting the model:

classes: list
	List of all the response classes.
input_relation: str
	Train relation.
X: list
	List of the predictors.
y: str
	Response column.
test_relation: str
	Relation to use to test the model. All the model methods are abstractions
	which will simplify the process. The test relation will be used by many
	methods to evaluate the model. If empty, the train relation will be 
	used as test. You can change it anytime by changing the test_relation
	attribute of the object.
	"""

    #
    # Special Methods
    #
    # ---#
    def __init__(self, cursor=None, n_neighbors: int = 5, p: int = 2):
        check_types(
            [
                ("n_neighbors", n_neighbors, [int, float], False),
                ("p", p, [int, float], False),
            ]
        )
        if not (cursor):
            cursor = read_auto_connect().cursor()
        else:
            check_cursor(cursor)
        self.type = "KNeighborsClassifier"
        self.category = "classifier"
        self.cursor = cursor
        self.n_neighbors = n_neighbors
        self.p = p

    #
    def __repr__(self):
        return "<KNeighborsClassifier>"

    #
    # Methods
    #
    # ---#
    def classification_report(self, cutoff=[], labels: list = []):
        """
	---------------------------------------------------------------------------
	Computes a classification report using multiple metrics to evaluate the model
	(AUC, accuracy, PRC AUC, F1...). In case of multiclass classification, it will 
	consider each category as positive and switch to the next one during the computation.

	Parameters
	----------
	cutoff: float/list, optional
		Cutoff for which the tested category will be accepted as prediction. 
		In case of multiclass classification, each tested category becomes 
		the positives and the others are merged into the negatives. The list will 
		represent the classes threshold. If it is empty, the best cutoff will be used.
	labels: list, optional
		List of the different labels to be used during the computation.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        check_types(
            [
                ("cutoff", cutoff, [int, float, list], False),
                ("labels", labels, [list], False),
            ]
        )
        if not (labels):
            labels = self.classes
        return classification_report(cutoff=cutoff, estimator=self, labels=labels)

    # ---#
    def confusion_matrix(self, pos_label=None, cutoff: float = -1):
        """
	---------------------------------------------------------------------------
	Computes the model confusion matrix.

	Parameters
	----------
	pos_label: int/float/str, optional
		Label to consider as positive. All the other classes will be merged and
		considered as negative in case of multi classification.
	cutoff: float, optional
		Cutoff for which the tested category will be accepted as prediction. If the 
		cutoff is not between 0 and 1, the entire confusion matrix will be drawn.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        check_types([("cutoff", cutoff, [int, float], False)])
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label in self.classes and cutoff <= 1 and cutoff >= 0:
            input_relation = self.deploySQL() + " WHERE predict_knc = '{}'".format(
                pos_label
            )
            y_score = "(CASE WHEN proba_predict > {} THEN 1 ELSE 0 END)".format(cutoff)
            y_true = "DECODE({}, '{}', 1, 0)".format(self.y, pos_label)
            result = confusion_matrix(y_true, y_score, input_relation, self.cursor)
            if pos_label == 1:
                return result
            else:
                return tablesample(
                    values={
                        "index": ["Non-{}".format(pos_label), "{}".format(pos_label)],
                        "Non-{}".format(pos_label): result.values[0],
                        "{}".format(pos_label): result.values[1],
                    },
                    table_info=False,
                )
        else:
            input_relation = "(SELECT *, ROW_NUMBER() OVER(PARTITION BY {}, row_id ORDER BY proba_predict DESC) AS pos FROM {}) knc_table_predict WHERE pos = 1".format(
                ", ".join(self.X), self.deploySQL()
            )
            return multilabel_confusion_matrix(
                self.y, "predict_knc", input_relation, self.classes, self.cursor
            )

    # ---#
    def deploySQL(self, predict: bool = False):
        """
	---------------------------------------------------------------------------
	Returns the SQL code needed to deploy the model. 

	Parameters
	----------
	predict: bool, optional
		If set to true, returns the prediction instead of the probability.

	Returns
	-------
	str/list
 		the SQL code needed to deploy the model.
		"""
        check_types([("predict", predict, [bool], False)])
        sql = [
            "POWER(ABS(x.{} - y.{}), {})".format(self.X[i], self.X[i], self.p)
            for i in range(len(self.X))
        ]
        sql = "POWER({}, 1 / {})".format(" + ".join(sql), self.p)
        sql = "ROW_NUMBER() OVER(PARTITION BY {}, row_id ORDER BY {})".format(
            ", ".join(["x.{}".format(item) for item in self.X]), sql
        )
        where = " AND ".join(["{} IS NOT NULL".format(item) for item in self.X])
        sql = "SELECT {}, {} AS ordered_distance, x.{}, y.{} AS predict_knc, row_id FROM (SELECT *, ROW_NUMBER() OVER() AS row_id FROM {} WHERE {}) x CROSS JOIN (SELECT * FROM {} WHERE {}) y".format(
            ", ".join(["x.{}".format(item) for item in self.X]),
            sql,
            self.y,
            self.y,
            self.test_relation,
            where,
            self.input_relation,
            where,
        )
        sql = "(SELECT row_id, {}, {}, predict_knc, COUNT(*) / {} AS proba_predict FROM ({}) z WHERE ordered_distance <= {} GROUP BY {}, {}, row_id, predict_knc) knc_table".format(
            ", ".join(self.X),
            self.y,
            self.n_neighbors,
            sql,
            self.n_neighbors,
            ", ".join(self.X),
            self.y,
        )
        if predict:
            sql = "(SELECT {}, {}, predict_knc FROM (SELECT {}, {}, predict_knc, ROW_NUMBER() OVER (PARTITION BY {} ORDER BY proba_predict DESC) AS order_prediction FROM {}) x WHERE order_prediction = 1) predict_knc_table".format(
                ", ".join(self.X),
                self.y,
                ", ".join(self.X),
                self.y,
                ", ".join(self.X),
                sql,
            )
        return sql

    # ---#
    def fit(self, input_relation: str, X: list, y: str, test_relation: str = ""):
        """
	---------------------------------------------------------------------------
	Trains the model.

	Parameters
	----------
	input_relation: str
		Train relation.
	X: list
		List of the predictors.
	y: str
		Response column.
	test_relation: str, optional
		Relation to use to test the model.

	Returns
	-------
	object
 		self
		"""
        check_types(
            [
                ("input_relation", input_relation, [str], False),
                ("X", X, [list], False),
                ("y", y, [str], False),
                ("test_relation", test_relation, [str], False),
            ]
        )
        self.input_relation = input_relation
        self.test_relation = test_relation if (test_relation) else input_relation
        self.X = [str_column(column) for column in X]
        self.y = str_column(y)
        self.cursor.execute(
            "SELECT DISTINCT {} FROM {} WHERE {} IS NOT NULL ORDER BY {} ASC".format(
                self.y, input_relation, self.y, self.y
            )
        )
        classes = self.cursor.fetchall()
        self.classes = [item[0] for item in classes]
        return self

    # ---#
    def lift_chart(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model Lift Chart.

	Parameters
	----------
	pos_label: int/float/str
		To draw a lift chart, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_knc = '{}'".format(
            pos_label
        )
        y_proba = "proba_predict"
        return lift_chart(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def prc_curve(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model PRC curve.

	Parameters
	----------
	pos_label: int/float/str
		To draw the PRC curve, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_knc = '{}'".format(
            pos_label
        )
        y_proba = "proba_predict"
        return prc_curve(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def roc_curve(self, pos_label=None):
        """
	---------------------------------------------------------------------------
	Draws the model ROC curve.

	Parameters
	----------
	pos_label: int/float/str
		To draw the ROC curve, one of the response column class has to be the 
		positive one. The parameter 'pos_label' represents this class.

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        if pos_label not in self.classes:
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        input_relation = self.deploySQL() + " WHERE predict_knc = '{}'".format(
            pos_label
        )
        y_proba = "proba_predict"
        return roc_curve(self.y, y_proba, input_relation, self.cursor, pos_label)

    # ---#
    def score(self, pos_label=None, cutoff: float = -1, method: str = "accuracy"):
        """
	---------------------------------------------------------------------------
	Computes the model score.

	Parameters
	----------
	pos_label: int/float/str, optional
		Label to consider as positive. All the other classes will be merged and
		considered as negative in case of multi classification.
	cutoff: float, optional
		Cutoff for which the tested category will be accepted as prediction. 
	method: str, optional
		The method to use to compute the score.
			accuracy    : Accuracy
			auc         : Area Under the Curve (ROC)
			best_cutoff : Cutoff which optimised the ROC Curve prediction.
			bm          : Informedness = tpr + tnr - 1
			csi         : Critical Success Index = tp / (tp + fn + fp)
			f1          : F1 Score 
			logloss     : Log Loss
			mcc         : Matthews Correlation Coefficient 
			mk          : Markedness = ppv + npv - 1
			npv         : Negative Predictive Value = tn / (tn + fn)
			prc_auc     : Area Under the Curve (PRC)
			precision   : Precision = tp / (tp + fp)
			recall      : Recall = tp / (tp + fn)
			specificity : Specificity = tn / (tn + fp) 

	Returns
	-------
	float
 		score
		"""
        check_types(
            [("cutoff", cutoff, [int, float], False), ("method", method, [str], False)]
        )
        pos_label = (
            self.classes[1]
            if (pos_label == None and len(self.classes) == 2)
            else pos_label
        )
        input_relation = "(SELECT * FROM {} WHERE predict_knc = '{}') final_knn_table".format(
            self.deploySQL(), pos_label
        )
        y_score = "(CASE WHEN proba_predict > {} THEN 1 ELSE 0 END)".format(cutoff)
        y_proba = "proba_predict"
        y_true = "DECODE({}, '{}', 1, 0)".format(self.y, pos_label)
        if (pos_label not in self.classes) and (method != "accuracy"):
            raise ParameterError(
                "'pos_label' must be one of the response column classes"
            )
        elif (cutoff >= 1 or cutoff <= 0) and (method != "accuracy"):
            cutoff = self.score(pos_label, 0.5, "best_cutoff")
        if method in ("accuracy", "acc"):
            if pos_label not in self.classes:
                return accuracy_score(
                    self.y,
                    "predict_knc",
                    self.deploySQL(True),
                    self.cursor,
                    pos_label=None,
                )
            else:
                return accuracy_score(y_true, y_score, input_relation, self.cursor)
        elif method == "auc":
            return auc(y_true, y_proba, input_relation, self.cursor)
        elif method == "prc_auc":
            return prc_auc(y_true, y_proba, input_relation, self.cursor)
        elif method in ("best_cutoff", "best_threshold"):
            return roc_curve(
                y_true, y_proba, input_relation, self.cursor, best_threshold=True
            )
        elif method in ("recall", "tpr"):
            return recall_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("precision", "ppv"):
            return precision_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("specificity", "tnr"):
            return specificity_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("negative_predictive_value", "npv"):
            return precision_score(y_true, y_score, input_relation, self.cursor)
        elif method in ("log_loss", "logloss"):
            return log_loss(y_true, y_proba, input_relation, self.cursor)
        elif method == "f1":
            return f1_score(y_true, y_score, input_relation, self.cursor)
        elif method == "mcc":
            return matthews_corrcoef(y_true, y_score, input_relation, self.cursor)
        elif method in ("bm", "informedness"):
            return informedness(y_true, y_score, input_relation, self.cursor)
        elif method in ("mk", "markedness"):
            return markedness(y_true, y_score, input_relation, self.cursor)
        elif method in ("csi", "critical_success_index"):
            return critical_success_index(y_true, y_score, input_relation, self.cursor)
        else:
            raise ParameterError(
                "The parameter 'method' must be in accuracy|auc|prc_auc|best_cutoff|recall|precision|log_loss|negative_predictive_value|specificity|mcc|informedness|markedness|critical_success_index"
            )

    # ---#
    def to_vdf(self, cutoff: float = -1, all_classes: bool = False):
        """
	---------------------------------------------------------------------------
	Returns the vDataFrame of the Prediction.

	Parameters
	----------
	cutoff: float, optional
		Cutoff used in case of binary classification. It is the probability to
		accept the category 1.
	all_classes: bool, optional
		If set to true, all the classes probabilities will be generated (one 
		column per category).

	Returns
	-------
	vDataFrame
 		the vDataFrame of the prediction
		"""
        check_types(
            [
                ("cutoff", cutoff, [int, float], False),
                ("all_classes", all_classes, [bool], False),
            ]
        )
        if all_classes:
            predict = [
                "ZEROIFNULL(AVG(DECODE(predict_knc, '{}', proba_predict, NULL))) AS \"{}_{}\"".format(
                    elem, self.y.replace('"', ""), elem
                )
                for elem in self.classes
            ]
            sql = "SELECT {}, {} FROM {} GROUP BY {}".format(
                ", ".join(self.X),
                ", ".join(predict),
                self.deploySQL(),
                ", ".join(self.X),
            )
        else:
            if (len(self.classes) == 2) and (cutoff <= 1 and cutoff >= 0):
                sql = "SELECT {}, (CASE WHEN proba_predict > {} THEN '{}' ELSE '{}' END) AS {} FROM {} WHERE predict_knc = '{}'".format(
                    ", ".join(self.X),
                    cutoff,
                    self.classes[1],
                    self.classes[0],
                    self.y,
                    self.deploySQL(),
                    self.classes[1],
                )
            elif len(self.classes) == 2:
                sql = "SELECT {}, proba_predict AS {} FROM {} WHERE predict_knc = '{}'".format(
                    ", ".join(self.X), self.y, self.deploySQL(), self.classes[1]
                )
            else:
                sql = "SELECT {}, predict_knc AS {} FROM {}".format(
                    ", ".join(self.X), self.y, self.deploySQL(True)
                )
        sql = "({}) x".format(sql)
        return vdf_from_relation(name="KNN", relation=sql, cursor=self.cursor)


# ---#
class KNeighborsRegressor:
    """
---------------------------------------------------------------------------
[Beta Version]
Creates a KNeighborsRegressor object by using the K Nearest Neighbors Algorithm. 
This object is using pure SQL to compute all the distances and final score. 

\u26A0 Warning : This Algorithm is computationally expensive. It is using a CROSS 
                 JOIN during the computation. The complexity is O(n * n), n 
                 being the total number of elements. As KNeighborsRegressor 
                 is using the p-distance, it is highly sensible to un-normalized 
                 data.

Parameters
----------
cursor: DBcursor, optional
	Vertica DB cursor. 
n_neighbors: int, optional
	Number of neighbors to consider when computing the score.
p: int, optional
	The p corresponding to the one of the p-distance (distance metric used during 
	the model computation).

Attributes
----------
After the object creation, all the parameters become attributes. 
The model will also create extra attributes when fitting the model:

input_relation: str
	Train relation.
X: list
	List of the predictors.
y: str
	Response column.
test_relation: str
	Relation to use to test the model. All the model methods are abstractions
	which will simplify the process. The test relation will be used by many
	methods to evaluate the model. If empty, the train relation will be 
	used as test. You can change it anytime by changing the test_relation
	attribute of the object.
	"""

    #
    # Special Methods
    #
    # ---#
    def __init__(self, cursor=None, n_neighbors: int = 5, p: int = 2):
        check_types(
            [
                ("n_neighbors", n_neighbors, [int, float], False),
                ("p", p, [int, float], False),
            ]
        )
        if not (cursor):
            cursor = read_auto_connect().cursor()
        else:
            check_cursor(cursor)
        self.type = "KNeighborsRegressor"
        self.category = "regressor"
        self.cursor = cursor
        self.n_neighbors = n_neighbors
        self.p = p

    # ---#
    def __repr__(self):
        return "<KNeighborsRegressor>"

    #
    # Methods
    #
    # ---#
    def deploySQL(self):
        """
	---------------------------------------------------------------------------
	Returns the SQL code needed to deploy the model. 

	Returns
	-------
	str
 		the SQL code needed to deploy the model.
		"""
        sql = [
            "POWER(ABS(x.{} - y.{}), {})".format(self.X[i], self.X[i], self.p)
            for i in range(len(self.X))
        ]
        sql = "POWER({}, 1 / {})".format(" + ".join(sql), self.p)
        sql = "ROW_NUMBER() OVER(PARTITION BY {}, row_id ORDER BY {})".format(
            ", ".join(["x.{}".format(item) for item in self.X]), sql
        )
        where = " AND ".join(["{} IS NOT NULL".format(item) for item in self.X])
        sql = "SELECT {}, {} AS ordered_distance, x.{}, y.{} AS predict_knr, row_id FROM (SELECT *, ROW_NUMBER() OVER() AS row_id FROM {} WHERE {}) x CROSS JOIN (SELECT * FROM {} WHERE {}) y".format(
            ", ".join(["x.{}".format(item) for item in self.X]),
            sql,
            self.y,
            self.y,
            self.test_relation,
            where,
            self.input_relation,
            where,
        )
        sql = "(SELECT {}, {}, AVG(predict_knr) AS predict_knr FROM ({}) z WHERE ordered_distance <= {} GROUP BY {}, {}, row_id) knr_table".format(
            ", ".join(self.X), self.y, sql, self.n_neighbors, ", ".join(self.X), self.y
        )
        return sql

    # ---#
    def fit(self, input_relation: str, X: list, y: str, test_relation: str = ""):
        """
	---------------------------------------------------------------------------
	Trains the model.

	Parameters
	----------
	input_relation: str
		Train relation.
	X: list
		List of the predictors.
	y: str
		Response column.
	test_relation: str, optional
		Relation to use to test the model.

	Returns
	-------
	object
 		self
		"""
        check_types(
            [
                ("input_relation", input_relation, [str], False),
                ("X", X, [list], False),
                ("y", y, [str], False),
                ("test_relation", test_relation, [str], False),
            ]
        )
        self.input_relation = input_relation
        self.test_relation = test_relation if (test_relation) else input_relation
        self.X = [str_column(column) for column in X]
        self.y = str_column(y)
        return self

    # ---#
    def regression_report(self):
        """
	---------------------------------------------------------------------------
	Computes a regression report using multiple metrics to evaluate the model
	(r2, mse, max error...). 

	Returns
	-------
	tablesample
 		An object containing the result. For more information, see
 		utilities.tablesample.
		"""
        return regression_report(self.y, "predict_knr", self.deploySQL(), self.cursor)

    # ---#
    def score(self, method: str = "r2"):
        """
	---------------------------------------------------------------------------
	Computes the model score.

	Parameters
	----------
	method: str, optional
		The method to use to compute the score.
			max    : Max Error
			mae    : Mean Absolute Error
			median : Median Absolute Error
			mse    : Mean Squared Error
			msle   : Mean Squared Log Error
			r2     : R squared coefficient
			var    : Explained Variance 

	Returns
	-------
	float
 		score
		"""
        check_types([("method", method, [str], False)])
        if method in ("r2", "rsquared"):
            return r2_score(self.y, "predict_knr", self.deploySQL(), self.cursor)
        elif method in ("mae", "mean_absolute_error"):
            return mean_absolute_error(
                self.y, "predict_knr", self.deploySQL(), self.cursor
            )
        elif method in ("mse", "mean_squared_error"):
            return mean_squared_error(
                self.y, "predict_knr", self.deploySQL(), self.cursor
            )
        elif method in ("msle", "mean_squared_log_error"):
            return mean_squared_log_error(
                self.y, "predict_knr", self.deploySQL(), self.cursor
            )
        elif method in ("max", "max_error"):
            return max_error(self.y, "predict_knr", self.deploySQL(), self.cursor)
        elif method in ("median", "median_absolute_error"):
            return median_absolute_error(
                self.y, "predict_knr", self.deploySQL(), self.cursor
            )
        elif method in ("var", "explained_variance"):
            return explained_variance(
                self.y, "predict_knr", self.deploySQL(), self.cursor
            )
        else:
            raise ParameterError(
                "The parameter 'method' must be in r2|mae|mse|msle|max|median|var"
            )

    # ---#
    def to_vdf(self):
        """
	---------------------------------------------------------------------------
	Returns the vDataFrame of the Prediction.

	Returns
	-------
	vDataFrame
 		the vDataFrame of the prediction
		"""
        sql = "(SELECT {}, {} AS {} FROM {}) x".format(
            ", ".join(self.X), "predict_knr", self.y, self.deploySQL()
        )
        return vdf_from_relation(
            name="KNeighborsRegressor", relation=sql, cursor=self.cursor
        )


# ---#
class LocalOutlierFactor:
    """
---------------------------------------------------------------------------
[Beta Version]
Creates a LocalOutlierFactor object by using the Local Outlier Factor algorithm 
as defined by Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng and Jörg 
Sander. This object is using pure SQL to compute all the distances and final 
score.

\u26A0 Warning : This Algorithm is computationally expensive. It is using a CROSS 
                 JOIN during the computation. The complexity is O(n * n), n 
                 being the total number of elements. As LocalOutlierFactor 
                 is using the p-distance, it is highly sensible to un-normalized 
                 data. A table will be created at the end of the learning phase.

Parameters
----------
name: str
	Name of the the model. As it is not a built in model, this name will be used
	to build the final table.
cursor: DBcursor, optional
	Vertica DB cursor.
n_neighbors: int, optional
	Number of neighbors to consider when computing the score.
p: int, optional
	The p of the p-distance (distance metric used during the model computation).

Attributes
----------
After the object creation, all the parameters become attributes. 
The model will also create extra attributes when fitting the model:

n_errors: int
	Number of errors during the LOF computation.
input_relation: str
	Train relation.
X: list
	List of the predictors.
key_columns: list
	Columns not used during the algorithm computation but which will be used
	to create the final relation.
	"""

    #
    # Special Methods
    #
    # ---#
    def __init__(self, name: str, cursor=None, n_neighbors: int = 20, p: int = 2):
        check_types(
            [
                ("name", name, [str], False),
                ("n_neighbors", n_neighbors, [int, float], False),
                ("p", p, [int, float], False),
            ]
        )
        if not (cursor):
            cursor = read_auto_connect().cursor()
        else:
            check_cursor(cursor)
        self.type = "LocalOutlierFactor"
        self.category = "anomaly_detection"
        self.name = name
        self.cursor = cursor
        self.n_neighbors = n_neighbors
        self.p = p

    # ---#
    def __repr__(self):
        return "<LocalOutlierFactor>"

    #
    # Methods
    #
    # ---#
    def fit(
        self, input_relation: str, X: list, key_columns: list = [], index: str = ""
    ):
        """
	---------------------------------------------------------------------------
	Trains the model.

	Parameters
	----------
	input_relation: str
		Train relation.
	X: list
		List of the predictors.
	key_columns: list, optional
		Columns not used during the algorithm computation but which will be used
		to create the final relation.
	index: str, optional
		Index to use to identify each row separately. It is highly recommanded to
		have one already in the main table to avoid creation of temporary tables.

	Returns
	-------
	object
 		self
		"""
        check_types(
            [
                ("input_relation", input_relation, [str], False),
                ("X", X, [list], False),
                ("key_columns", key_columns, [list], False),
                ("index", index, [str], False),
            ]
        )
        X = [str_column(column) for column in X]
        self.X = X
        self.key_columns = [str_column(column) for column in key_columns]
        self.input_relation = input_relation
        cursor = self.cursor
        n_neighbors = self.n_neighbors
        p = self.p
        relation_alpha = "".join(ch for ch in input_relation if ch.isalnum())
        schema, relation = schema_relation(input_relation)
        if not (index):
            index = "id"
            relation_alpha = "".join(ch for ch in relation if ch.isalnum())
            main_table = "VERTICAPY_MAIN_{}".format(relation_alpha)
            schema = "v_temp_schema"
            try:
                cursor.execute(
                    "DROP TABLE IF EXISTS v_temp_schema.{}".format(main_table)
                )
            except:
                pass
            sql = "CREATE LOCAL TEMPORARY TABLE {} ON COMMIT PRESERVE ROWS AS SELECT ROW_NUMBER() OVER() AS id, {} FROM {} WHERE {}".format(
                main_table,
                ", ".join(X + key_columns),
                input_relation,
                " AND ".join(["{} IS NOT NULL".format(item) for item in X]),
            )
            cursor.execute(sql)
        else:
            main_table = input_relation
        sql = [
            "POWER(ABS(x.{} - y.{}), {})".format(X[i], X[i], p) for i in range(len(X))
        ]
        distance = "POWER({}, 1 / {})".format(" + ".join(sql), p)
        sql = "SELECT x.{} AS node_id, y.{} AS nn_id, {} AS distance, ROW_NUMBER() OVER(PARTITION BY x.{} ORDER BY {}) AS knn FROM {}.{} AS x CROSS JOIN {}.{} AS y".format(
            index,
            index,
            distance,
            index,
            distance,
            schema,
            main_table,
            schema,
            main_table,
        )
        sql = "SELECT node_id, nn_id, distance, knn FROM ({}) distance_table WHERE knn <= {}".format(
            sql, n_neighbors + 1
        )
        try:
            cursor.execute(
                "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_DISTANCE_{}".format(
                    relation_alpha
                )
            )
        except:
            pass
        sql = "CREATE LOCAL TEMPORARY TABLE VERTICAPY_DISTANCE_{} ON COMMIT PRESERVE ROWS AS {}".format(
            relation_alpha, sql
        )
        cursor.execute(sql)
        kdistance = "(SELECT node_id, nn_id, distance AS distance FROM v_temp_schema.VERTICAPY_DISTANCE_{} WHERE knn = {}) AS kdistance_table".format(
            relation_alpha, n_neighbors + 1
        )
        lrd = "SELECT distance_table.node_id, {} / SUM(CASE WHEN distance_table.distance > kdistance_table.distance THEN distance_table.distance ELSE kdistance_table.distance END) AS lrd FROM (v_temp_schema.VERTICAPY_DISTANCE_{} AS distance_table LEFT JOIN {} ON distance_table.nn_id = kdistance_table.node_id) x GROUP BY 1".format(
            n_neighbors, relation_alpha, kdistance
        )
        try:
            cursor.execute(
                "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_LRD_{}".format(
                    relation_alpha
                )
            )
        except:
            pass
        sql = "CREATE LOCAL TEMPORARY TABLE VERTICAPY_LRD_{} ON COMMIT PRESERVE ROWS AS {}".format(
            relation_alpha, lrd
        )
        cursor.execute(sql)
        sql = "SELECT x.node_id, SUM(y.lrd) / (MAX(x.node_lrd) * {}) AS LOF FROM (SELECT n_table.node_id, n_table.nn_id, lrd_table.lrd AS node_lrd FROM v_temp_schema.VERTICAPY_DISTANCE_{} AS n_table LEFT JOIN v_temp_schema.VERTICAPY_LRD_{} AS lrd_table ON n_table.node_id = lrd_table.node_id) x LEFT JOIN v_temp_schema.VERTICAPY_LRD_{} AS y ON x.nn_id = y.node_id GROUP BY 1".format(
            n_neighbors, relation_alpha, relation_alpha, relation_alpha
        )
        try:
            cursor.execute(
                "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_LOF_{}".format(
                    relation_alpha
                )
            )
        except:
            pass
        sql = "CREATE LOCAL TEMPORARY TABLE VERTICAPY_LOF_{} ON COMMIT PRESERVE ROWS AS {}".format(
            relation_alpha, sql
        )
        cursor.execute(sql)
        sql = "SELECT {}, (CASE WHEN lof > 1e100 OR lof != lof THEN 0 ELSE lof END) AS lof_score FROM {} AS x LEFT JOIN v_temp_schema.VERTICAPY_LOF_{} AS y ON x.{} = y.node_id".format(
            ", ".join(X + self.key_columns), main_table, relation_alpha, index
        )
        cursor.execute("CREATE TABLE {} AS {}".format(self.name, sql))
        cursor.execute(
            "SELECT COUNT(*) FROM {}.VERTICAPY_LOF_{} z WHERE lof > 1e100 OR lof != lof".format(
                schema, relation_alpha
            )
        )
        self.n_errors = cursor.fetchone()[0]
        cursor.execute(
            "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_MAIN_{}".format(
                relation_alpha
            )
        )
        cursor.execute(
            "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_DISTANCE_{}".format(
                relation_alpha
            )
        )
        cursor.execute(
            "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_LRD_{}".format(relation_alpha)
        )
        cursor.execute(
            "DROP TABLE IF EXISTS v_temp_schema.VERTICAPY_LOF_{}".format(relation_alpha)
        )
        return self

    # ---#
    def info(self):
        """
	---------------------------------------------------------------------------
	Displays some information about the model.
		"""
        if self.n_errors == 0:
            print("All the LOF scores were computed.")
        else:
            print(
                "{} error(s) happened during the computation. These ones were imputed by 0 as it is highly probable that the {}-Neighbors of these points were confounded (usual problem of the LOF computation).\nIncrease the number of Neighbors to decrease the number of errors.".format(
                    self.n_errors, self.n_neighbors
                )
            )

    # ---#
    def plot(self, X: list = [], tablesample: float = -1):
        """
	---------------------------------------------------------------------------
	Draws the model is the number of predictors is 2 or 3.

	Parameters
	----------
	X: list, optional
		List of the predictors to display. The score will stay the same. 
	tablesample: float, optional
		Sample of data to display. If this number is not between 0 and 1 all
		the data points will be displayed.

    Returns
    -------
    Figure
        Matplotlib Figure
		"""
        check_types(
            [("X", X, [list], False), ("tablesample", tablesample, [int, float], False)]
        )
        X = self.X if not (X) else X
        return lof_plot(self.name, X, "lof_score", self.cursor, tablesample)

    # ---#
    def to_vdf(self):
        """
	---------------------------------------------------------------------------
	Creates a vDataFrame of the model.

	Returns
	-------
	vDataFrame
 		model vDataFrame
		"""
        return vDataFrame(self.name, self.cursor)
